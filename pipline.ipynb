{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "###CAMERA_CALIBRATION\n",
    "###\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "img_chessboard = glob.glob('camera_cal/calibration*.jpg')\n",
    "# prepare object points\n",
    "nx = 9# number of inside corners in x\n",
    "ny = 6# number of inside corners in y\n",
    "objpoints = [] # 3d points \n",
    "imgpoints = [] # 2d points \n",
    "###this code is the same as those appears in lecture video\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "for index, filename in enumerate(img_chessboard):\n",
    "    img = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    \n",
    "    # If found, draw corners    \n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        #plt.imshow(img)\n",
    "\n",
    "#get mtx and dist\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "print(\"Get mtx and dist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "###UNDISTORT IMAGE\n",
    "###\n",
    "#undistort image\n",
    "# dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "def undist(img,mtx,dist):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)\n",
    "print(\"undistort function was built\")\n",
    "\n",
    "\n",
    "###undist visulization\n",
    "##code below from correct for distortion lecture\n",
    "img= mpimg.imread(\"camera_cal/calibration1.jpg\")\n",
    "undistorted = undist(img, mtx, dist)\n",
    "###\n",
    "###visualization pipline\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "#COLOR AND GRADIENT THRESHOLD\n",
    "###\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    grad_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Calculate the magnitude \n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    grad = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = np.zeros_like(grad)\n",
    "    #binary_output = np.copy(img) # Remove this line\n",
    "    ##apply the threshold\n",
    "    binary_output[(grad >= thresh[0]) & (grad <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def color_threshold(s_channel, thresh=(90, 255)):\n",
    "    hls = cv2.cvtColor(warped, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"threshold pipline was built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline(img, s_thresh=(90, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    return color_binary\n",
    "    \n",
    "print(\"build pipline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "##read test image\n",
    "###\n",
    "img_test = glob.glob('test_images/test*.jpg')\n",
    "sample=[]\n",
    "for index, filename in enumerate(img_test):\n",
    "    img = cv2.imread(filename)\n",
    "    sample.append(img)\n",
    "    \n",
    "# test_images = []\n",
    "# for file in os.listdir('test_images/'):\n",
    "#     if(file != '.DS_Store'):\n",
    "#         test_images.append(\"test_images/\"+file)\n",
    "        \n",
    "print(\"test images loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "##test color threshold\n",
    "###\n",
    "\n",
    "    \n",
    "case1 = sample[2]\n",
    "undistortion = undist(case1, mtx, dist)\n",
    "warped = undistortion.copy()\n",
    "\n",
    "\n",
    "case_Result = color_threshold(warped, thresh=(90, 255))\n",
    "# result = pipeline(warped)\n",
    "\n",
    "##plot case result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(warped)\n",
    "ax1.set_title('warped Image', fontsize=50)\n",
    "ax2.imshow(case_Result, cmap='gray')\n",
    "ax2.set_title('Thresholded S', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "##test threshold\n",
    "###\n",
    "\n",
    "    \n",
    "case2 = sample[1]\n",
    "undistortion2 = undist(case2, mtx, dist)\n",
    "warped_2 = undistortion2.copy()\n",
    "\n",
    "\n",
    "\n",
    "# case_Result = color_threshold(warped, thresh=(90, 255))\n",
    "result = pipeline(warped_2)\n",
    "\n",
    "##plot case result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(warped_2)\n",
    "ax1.set_title('warped Image', fontsize=50)\n",
    "ax2.imshow(result, cmap='gray')\n",
    "ax2.set_title('Thresholded S and Sobel', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perspective Transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def image_unwarp(undisto,img_size):\n",
    "\n",
    "#     left_top_src = [550, 580]\n",
    "#     left_down_src =[800, 580]\n",
    "#     right_top_src = [400, 680] \n",
    "#     right_down_src = [1050, 680]\n",
    "#     src = np.array([ left_top_src,left_down_src,right_down_src,right_top_src], dtype=np.float32)\n",
    "\n",
    "#     left_top_dst = [300, 310]\n",
    "#     left_down_dst = [700, 370]\n",
    "#     right_top_dst = [300, 870]\n",
    "#     right_down_dst = [700, 800]\n",
    "#     dst = np.array([left_top_dst,left_down_dst,right_down_dst,right_top_dst], dtype=np.float32)\n",
    "    \n",
    "#     M = cv2.getPerspectiveTransform(src, dst)\n",
    "#         # Warp the image using OpenCV warpPerspective()\n",
    "#     warped_img = cv2.warpPerspective(undisto, M, img_size)\n",
    "#     #warped_img = cv2.transpose(warped_img)\n",
    "#     return warped_img, M\n",
    "\n",
    "####this warper function is copied from github\n",
    "##my warper did not work\n",
    "def image_unwarp(img, bird_view = True):\n",
    "    xsize = img.shape[1]\n",
    "    ysize = img.shape[0]\n",
    "\n",
    "    p1_src = [175, ysize]\n",
    "    p2_src = [560, 470]\n",
    "    p3_src = [730, 470]\n",
    "    p4_src = [1155, ysize]\n",
    "    src = np.array([p1_src, p2_src, p3_src, p4_src], dtype=np.float32)\n",
    "\n",
    "    p1_dst = [250, ysize]\n",
    "    p2_dst = [250, 0]\n",
    "    p3_dst = [1030, 0]\n",
    "    p4_dst = [1030, ysize]\n",
    "    dst = np.array([p1_dst, p2_dst, p3_dst, p4_dst], dtype=np.float32)\n",
    "    \n",
    "    if(bird_view):\n",
    "        # if we need to change to bird view \n",
    "        # given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    else:\n",
    "        # else switch src and dst, change back from bird view\n",
    "        M = cv2.getPerspectiveTransform(dst, src)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "    \n",
    "\n",
    "##test perspective transform\n",
    "\n",
    "gray_case = cv2.cvtColor(warped,cv2.COLOR_BGR2GRAY)\n",
    "img_size=(gray_case.shape[1],img.shape[0])\n",
    "\n",
    "\n",
    "top_down, M= image_unwarp(undistortion)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(warped)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s_img = top_down[:,:,2]\n",
    "histogram2 = np.sum(top_down[top_down.shape[0]/2:,:], axis=0)\n",
    "plt.plot(histogram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###plot S channel\n",
    "\n",
    "histogram = np.sum(s_img[s_img.shape[0]/2:,:], axis=0)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###find lane line \n",
    "import fit_polynomial\n",
    "\n",
    "gray_lane = cv2.cvtColor(top_down,cv2.COLOR_BGR2GRAY)\n",
    "ploty, left_fitx, right_fitx, leftx,rightx= fit_polynomial.fit_polynomial(gray_lane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "#measure curvature\n",
    "###\n",
    "mark_size = 3\n",
    "# leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "# rightx = rightx[::-1] \n",
    "\n",
    "# plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "# plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silding_window_search\n",
    "gray_lane = cv2.cvtColor(top_down,cv2.COLOR_BGR2GRAY)\n",
    "window = silding_window_search.get_window_centroids_result(gray_lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "#Draw lane line \n",
    "###\n",
    "warp_zero = np.zeros_like(case_Result).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "# newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "# gray_topdown = cv2.cvtColor(top_down,cv2.COLOR_BGR2GRAY)\n",
    "# img_size=(gray_topdown.shape[1],img.shape[0])\n",
    "# Combine the result with the original image\n",
    "newwarp, M= image_unwarp(color_warp,bird_view=False)\n",
    "_result = cv2.addWeighted(undistortion, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(_result)\n",
    "\n",
    "print(\"get lane line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####\n",
    "##run the video\n",
    "###\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(_img):\n",
    "    undist_v = undist(_img,mtx,dist)\n",
    "    V_Result = color_threshold(undist_v, thresh=(90, 255))\n",
    "    w_img, M= image_unwarp(undist_v)\n",
    "    \n",
    "    _lane = cv2.cvtColor(w_img,cv2.COLOR_BGR2GRAY)\n",
    "    ploty, left_fitx, right_fitx, leftx,rightx= fit_polynomial.fit_polynomial(_lane)\n",
    "    \n",
    "    warp_z = np.zeros_like(V_Result).astype(np.uint8)\n",
    "    color_w = np.dstack((warp_z, warp_z, warp_z))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_w, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    # newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # gray_topdown = cv2.cvtColor(top_down,cv2.COLOR_BGR2GRAY)\n",
    "    # img_size=(gray_topdown.shape[1],img.shape[0])\n",
    "    # Combine the result with the original image\n",
    "    newwarp, M= image_unwarp(color_warp,bird_view=False)\n",
    "    _result = cv2.addWeighted(undist_v, 1, newwarp, 0.3, 0)\n",
    "    return _result\n",
    "print(\"process image function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = '_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIDEO RESULT:\n",
    "\n",
    "PRETTY GOOD! You can get my test result in _output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##proc all test images\n",
    "test_images = []\n",
    "for file in os.listdir('test_images/'):\n",
    "    if(file != '.DS_Store'):\n",
    "        test_images.append(\"test_images/\"+file)\n",
    "print(\"read all test file\")\n",
    "prefix = 'output_images/' \n",
    "im_index = 0\n",
    "for t_file in  test_images:\n",
    "    \n",
    "    t_img = cv2.imread(t_file)\n",
    "    \n",
    "    t_result = process_image(t_img)\n",
    "    im_index = im_index+1\n",
    "    cv2.imwrite(prefix+str(im_index)+\".jpg\",t_result)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test images' output can be found in output_images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:driving]",
   "language": "python",
   "name": "conda-env-driving-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
